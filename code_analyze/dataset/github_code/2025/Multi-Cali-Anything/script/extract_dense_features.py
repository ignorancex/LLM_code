import argparse
import os
import numpy as np
import pycolmap
import pixsfm.refine_hloc
from pathlib import Path
from typing import Literal, List
import sqlite3
import PIL

FEATURE_PATCH_WIDTH = 16
FEATURE_PATCH_HEIGHT = 16
FEATURE_PATCH_CHANNEL = 128

def extract_dense_features(
    dataset_path : str,
    reconstructions_path : str,
    output_path : str,
    mode : Literal["colmap", "pixelsfm"],
    patch_width : int,
    patch_height : int,
    frame_names : List[str],
    overwrite : bool
):
    # Create and connect to the SQLite database.
    if os.path.isfile(output_path):
        if overwrite:
            os.remove(output_path)
    else:
        overwrite = True
    db = sqlite3.connect(output_path)
    # Create the table.
    if overwrite:
        db.execute(
        """
            CREATE TABLE dense_features(
                frame_name INTEGER,
                camera_name INTEGER,
                keypoint_id INTEGER,
                corner_x INTEGER,
                corner_y INTEGER,
                dense_feature BLOB,
                PRIMARY KEY (frame_name, camera_name, keypoint_id)
            )
        """
        )
        db.commit()
    # Instantiate the extractor.
    sfm = pixsfm.refine_hloc.PixSfM({"dense_features": {"max_edge": 4096}})
    # For each frame.
    for frame_folder_name in sorted(os.listdir(reconstructions_path)):
        # Folder name format: "frame[6-digit frame name]".
        frame_name = frame_folder_name[5:]
        if len(frame_names) > 0 and frame_name not in frame_names:
            continue
        print("============================= Frame {} =============================".format(frame_name))
        # Clear the existing data for the frame.
        db.execute("DELETE FROM dense_features WHERE frame_name = ?", (int(frame_name),))
        db.commit()
        # Load the reconstruction.
        if mode == "colmap":
            recon = pycolmap.Reconstruction(os.path.join(reconstructions_path, frame_folder_name, "sparse", "0"))
        else:
            recon = pycolmap.Reconstruction(os.path.join(reconstructions_path, frame_folder_name, "refined"))
        # For each image.
        for image in sorted([image for imageID, image in recon.images.items()], key=lambda x: x.name):
            camera_name = image.name[6:12]
            print("==== Camera {} ====".format(camera_name))
            # Extract dense features.
            image_path = os.path.join(dataset_path, frame_folder_name, image.name)
            image_size = PIL.Image.open(image_path).size
            assert image_size[0] >= patch_width and image_size[1] >= patch_height, "Image size is smaller than the patch size."
            dense_features = sfm.extractor(Path(image_path), overwrite_sparse=False, as_dict=True)[0]["patches"][0, :, :, :]
            # For each keypoint.
            for keypoint_id, keypoint in enumerate(image.points2D):
                keypoint_pos = keypoint.xy
                if keypoint.point3D_id == 2 ** 64 - 1:
                    continue
                # Get the dense feature.
                corner_x = max(0, int(round(keypoint_pos[0])) - patch_width // 2)
                corner_y = max(0, int(round(keypoint_pos[1])) - patch_height // 2)
                dense_feature = dense_features[corner_y:corner_y + patch_height, corner_x:corner_x + patch_width, :]
                # Insert the dense feature into the database.
                db.execute(
                """
                    INSERT INTO dense_features (frame_name, camera_name, keypoint_id, corner_x, corner_y, dense_feature)
                    VALUES (?, ?, ?, ?, ?, ?)
                """,
                    (int(frame_name), int(camera_name), keypoint_id, corner_x, corner_y, dense_feature.tobytes())
                )
            # Commit for each image/camera.
            db.commit()
    # Close the database.
    db.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        prog="extract_dense_features.py",
        description="""
                        Run Pixel-Perfect SfM feature extractor on the images generated by "gather_images.py".
                        Reconstruction results are needed because the dense feature maps are too large to be stored in the disk.
                        Instead, only patches around the keypoints are stored.
                        The result will be stored in a SQLite database.
                    """,
        allow_abbrev=True
    )
    parser.add_argument("dataset", help="Path to multiface dataset.")
    parser.add_argument("reconstructions", help="Path to reconstruction results generated by 'colmap_batch.py' or 'pixelsfm_batch.py'.")
    parser.add_argument("output", help="Path to the output SQLite database.")
    parser.add_argument("--mode", help="Mode of reconstructions. For colmap, models should be placed in <dataset folder>/<frame folder>/sparse/0/. For pixelsfm, models should be placed in <dataset folder>/<frame folder>/refined/.", choices=["colmap", "pixelsfm"], default="colmap")
    parser.add_argument("--patch_width", help="Patch width of the dense feature maps.", type=int, default=FEATURE_PATCH_WIDTH)
    parser.add_argument("--patch_height", help="Patch height of the dense feature maps.", type=int, default=FEATURE_PATCH_HEIGHT)
    parser.add_argument("--frame_names", type=str, nargs='*', help="The list of frame names to be processed. If not specified, all frames will be processed.")
    parser.add_argument("--overwrite", type=int, help="Whether to overwrite the existing database.", choices=[0, 1], default=0)
    args = parser.parse_args()
    dataset_path = args.dataset
    reconstructions_path = args.reconstructions
    output_path = args.output
    mode = args.mode
    patch_width = args.patch_width
    patch_height = args.patch_height
    frame_names = args.frame_names if args.frame_names is not None else []
    overwrite = bool(args.overwrite)
    extract_dense_features(dataset_path, reconstructions_path, output_path, mode, patch_width, patch_height, frame_names, overwrite)
