"""Heterograph NN modules"""
import torch as th
import torch.nn as nn

class HeteroGraphConv(nn.Module):
    #this is the proposed message traverse layer.
    def __init__(self, mods, dim, num_rel):
        super(HeteroGraphConv, self).__init__()
        self.mods = nn.ModuleDict(mods)
        # Do not break if graph has 0-in-degree nodes.
        # Because there is no general rule to add self-loop for heterograph.
        for _, v in self.mods.items():
            set_allow_zero_in_degree_fn = getattr(v, 'set_allow_zero_in_degree', None)
            if callable(set_allow_zero_in_degree_fn):
                set_allow_zero_in_degree_fn(True)
        self.kn = th.nn.Linear(dim, dim, bias=False)
        self.qn = th.nn.Linear(dim, dim, bias=False)
        self.vn = th.nn.Linear(dim, dim, bias=False)

        self.w1 = nn.Parameter(th.FloatTensor(size=(1, dim)))
        self.w2 = nn.Parameter(th.FloatTensor(size=(1, dim)))
        gain = nn.init.calculate_gain('relu')
        nn.init.xavier_normal_(self.w1, gain=gain)
        nn.init.xavier_normal_(self.w2, gain=gain)
        self.num_rel = num_rel

    def agg_fn(self, tensors, dsttype):
        kv = []
        qv = []
        vv = []
        for i in range(self.num_rel):
            kv.append(self.kn(tensors[i]))
            qv.append(self.qn(tensors[i]))
            vv.append(self.vn(tensors[i]))
        alpha = []
        for i in range(self.num_rel):
            #p = (kv[i] / (th.sum(kv[i]**2, dim=3)**0.5 + 1e-9).unsqueeze(dim=3)) * (qv[0]/(th.sum(qv[0]**2, dim=3)**0.5+1e-9).unsqueeze(dim=3))
            p = kv[i] * self.w1 + qv[0] * self.w2
            #p = (kv[i]) * (qv[0]) / 64
            p = p.sum(dim=3)
            alpha.append(p)
        alpha = th.cat(alpha, dim=2)
        mask = th.zeros_like(alpha) - float("Inf")
        mask = th.where(alpha==0, mask, th.zeros_like(mask))
        alpha = alpha + mask
        alpha = th.softmax(alpha, dim=2)
        tensors = th.cat(vv, dim=2)
        tensors = tensors.permute(3, 0, 1, 2)
        out = tensors * alpha
        out = out.sum(dim=3)
        out = out.unsqueeze(dim=-1)
        out = out.permute(1, 2, 3, 0)
        return out

    def forward(self, g, inputs, mod_args=None, mod_kwargs=None):
        """Forward computation

        Invoke the forward function with each module and aggregate their results.

        Parameters
        ----------
        g : DGLHeteroGraph
            Graph data.
        inputs : dict[str, Tensor] or pair of dict[str, Tensor]
            Input node features.
        mod_args : dict[str, tuple[any]], optional
            Extra positional arguments for the sub-modules.
        mod_kwargs : dict[str, dict[str, any]], optional
            Extra key-word arguments for the sub-modules.

        Returns
        -------
        dict[str, Tensor]
            Output representations for every types of nodes.
        """
        if mod_args is None:
            mod_args = {}
        if mod_kwargs is None:
            mod_kwargs = {}
        outputs = {nty : [] for nty in g.dsttypes}
        if isinstance(inputs, tuple) or g.is_block:
            if isinstance(inputs, tuple):
                src_inputs, dst_inputs = inputs
            else:
                src_inputs = inputs
                dst_inputs = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}

            for stype, etype, dtype in g.canonical_etypes:
                rel_graph = g[stype, etype, dtype]
                if rel_graph.number_of_edges() == 0:
                    continue
                if stype not in src_inputs or dtype not in dst_inputs:
                    continue
                dstdata = self.mods[etype](
                    rel_graph,
                    (src_inputs[stype], dst_inputs[dtype]),
                    *mod_args.get(etype, ()),
                    **mod_kwargs.get(etype, {}))
                outputs[dtype].append(dstdata)
        else:
            for stype, etype, dtype in g.canonical_etypes:
                rel_graph = g[stype, etype, dtype]
                if rel_graph.number_of_edges() == 0:
                    continue
                if stype not in inputs:
                    continue
                dstdata = self.mods[etype](
                    rel_graph,
                    inputs[stype],
                    *mod_args.get(etype, ()),
                    **mod_kwargs.get(etype, {}))
                outputs[dtype].append(dstdata)
        rsts = {}
        for nty, alist in outputs.items():
            if len(alist) != 0:
                rsts[nty] = self.agg_fn(alist, nty)
        return rsts


def get_aggregate_fn(agg):
    """Internal function to get the aggregation function for node data
    generated from different relations.

    Parameters
    ----------
    agg : str
        Method for aggregating node features generated by different relations.
        Allowed values are 'sum', 'max', 'min', 'mean', 'stack'.

    Returns
    -------
    callable
        Aggregator function that takes a list of tensors to aggregate
        and returns one aggregated tensor.
    """
    if agg == 'sum':
        fn = th.sum
    elif agg == 'max':
        fn = lambda inputs, dim: th.max(inputs, dim=dim)[0]
    elif agg == 'min':
        fn = lambda inputs, dim: th.min(inputs, dim=dim)[0]
    elif agg == 'mean':
        fn = th.mean
    elif agg == 'stack':
        fn = None  # will not be called
    else:
        raise DGLError('Invalid cross type aggregator. Must be one of '
                       '"sum", "max", "min", "mean" or "stack". But got "%s"' % agg)
    if agg == 'stack':
        def stack_agg(inputs, dsttype):  # pylint: disable=unused-argument
            if len(inputs) == 0:
                return None
            return th.stack(inputs, dim=1)
        return stack_agg
    else:
        def aggfn(inputs, dsttype):  # pylint: disable=unused-argument
            if len(inputs) == 0:
                return None
            stacked = th.stack(inputs, dim=0)
            return fn(stacked, dim=0)
        return aggfn
