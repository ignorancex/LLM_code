# -*- coding: utf-8 -*-
"""pln_pp_4Res_BP_NatImg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qELyIWD2pH_3DOvmoG4y7UuS6QyCo5Yd
"""

from google.colab import drive
drive.mount('/content/drive')

img_rows, img_cols = 224, 224 #number of rows and columns to convert the images to
input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last

import tensorflow as tf

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator()
valid_datagen = ImageDataGenerator()

train_generator1 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/natimdb/train/',
        classes = ['air&car','bike&person'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

valid_generator1 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/natimdb/valid/',
        classes = ['air&car','bike&person'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

train_generator21 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/natimdb/train/',
        classes = ['airplane','car'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

valid_generator21 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/natimdb/valid/',
        classes = ['airplane','car'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

train_generator22 = train_datagen.flow_from_directory(
        '/content/drive/My Drive/db/natimdb/train/',
        classes = ['motorbike','person'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

valid_generator22 = valid_datagen.flow_from_directory(
        '/content/drive/My Drive/db/natimdb/valid/',
        classes = ['motorbike','person'],
        target_size=(img_rows, img_cols),batch_size=32,class_mode='binary')

base_model1 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)
base_model21 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)
base_model22 = tf.keras.applications.ResNet50(weights='imagenet', include_top = False)

for layer in base_model1.layers:   layer.trainable = False
for layer in base_model21.layers:   layer.trainable = False
for layer in base_model22.layers:   layer.trainable = False

x = base_model1.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)

model1 = tf.keras.models.Model(inputs=base_model1.input, outputs=preds)

x = base_model21.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)

model21 = tf.keras.models.Model(inputs=base_model21.input, outputs=preds)


x = base_model22.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)

x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
x = tf.keras.layers.Dense(512, activation='relu')(x)
preds = tf.keras.layers.Dense(1, activation ='sigmoid')(x)


model22 = tf.keras.models.Model(inputs=base_model22.input, outputs=preds)

model1.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])
model21.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])
model22.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])

cb1= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)

cb2= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)

cb3= tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto',
    baseline=None, restore_best_weights=True
)


history = model1.fit(
      train_generator1,
      steps_per_epoch=train_generator1.n//train_generator1.batch_size,
      epochs=25,
      validation_data=valid_generator1,callbacks=[cb1],
      validation_steps=25)

history = model21.fit(
      train_generator21,
      steps_per_epoch=train_generator21.n//train_generator21.batch_size,
      epochs=25,
      validation_data=valid_generator21,callbacks=[cb2],
      validation_steps=10)

history = model22.fit(
      train_generator22,
      steps_per_epoch=train_generator22.n//train_generator22.batch_size,
      epochs=25,
      validation_data=valid_generator22,callbacks=[cb3],
      validation_steps=10)

import numpy as np
from google.colab import files
from keras.preprocessing import image
import cv2
import os
import glob

ct_bike=0; ct_ship=0; ct_motorbike=0; ct_person=0;

img_dir = '/content/drive/My Drive/db/natimdb/test/airplane/' 
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classesb1 = model1.predict(images, batch_size=10)
  classesb21 = model21.predict(images, batch_size=10)
  #classesb22 = model22.predict(images, batch_size=10)
  #print('airplane:',classesb1[0],classesb21[0])
  if((classesb1[0] < .5) and (classesb21[0] < .5)):    ct_bike=ct_bike+1

print('./')
os.chdir('/content/')
import os

img_dir = '/content/drive/My Drive/db/natimdb/test/car/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classess1 = model1.predict(images, batch_size=10)
  classess21 = model21.predict(images, batch_size=10)
  #classess22 = model22.predict(images, batch_size=10)
  #print('car:',classess1[0],classess21[0])
  if((classess1[0] < .5) and (classess21[0] > .5)):    ct_ship=ct_ship+1

print('./')
os.chdir('/content/')
import os
img_dir = '/content/drive/My Drive/db/natimdb/test/motorbike/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classest1 = model1.predict(images, batch_size=10)
  #classest21 = model21.predict(images, batch_size=10)
  classest22 = model22.predict(images, batch_size=10)
  #print('tracs:',classest1[0],classest22[0])
  if((classest1[0] > .5) and (classest22[0] < .5)):    ct_motorbike=ct_motorbike+1

print('./')
os.chdir('/content/')
import os
img_dir = '/content/drive/My Drive/db/natimdb/test/person/' # Enter Directory of all images.
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
data_path = os. path. join(img_dir,'*g')
files = glob. glob(data_path)
data = []
for f1 in files:
  img = image.load_img(f1, target_size=(324, 324))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classesw1 = model1.predict(images, batch_size=10)
  #classesw21 = model21.predict(images, batch_size=10)
  classesw22 = model22.predict(images, batch_size=10)
  #print('persons:',classesw1[0],classesw22[0])
  if((classesw1[0] > .5) and (classesw22[0] > .5)):    ct_person=ct_person+1

print('./')
print(ct_bike,ct_ship,ct_motorbike,ct_person)  
