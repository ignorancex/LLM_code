# -*- coding: utf-8 -*-

import logging
import os
import pickle
import re
import sys
import shutil
import subprocess
from collections import namedtuple
from glob import glob

import yaml
import torch
from torch.autograd import Variable
import torch.onnx

from aw_nas import utils
from aw_nas.main import _init_component
from aw_nas.utils.exception import expect, ConfigException
from aw_nas.hardware.base import BaseHardwareCompiler
from aw_nas.utils.log import LEVEL as _LEVEL
from aw_nas.rollout.general import GeneralSearchSpace
from aw_nas.hardware.utils import Prim


class XavierCompiler(BaseHardwareCompiler):
    """
    Class Description: 
        A hardware interface class for NVIDIA Xavier GPU
        We profile search space primitives on at a time with TensorRT on Xavier GPU.
    Parent Class: BaseHardwareCompiler
    Registry Name: "xavier"
    Member functions:
        compile()    : export search space primitives to ONNX models
        parse_file() : parse TensorRT output file to get latency values
    """

    NAME = "xavier"

    def __init__(self, dcf=None, mode="debug", calib_iter=0, gpu=0, **kwargs):
        super(XavierCompiler, self).__init__()
        self.dcf = dcf
        self.mode = mode
        self.calib_iter = calib_iter
        self._debug_output = _LEVEL <= logging.DEBUG  # debug output
        self.gpu = gpu



    def compile(self, compile_name, net_config, result_dir):
        """
            Export search space primitives to ONNX model. 
            Each ONNX model contains a single primitive.
            
            compile_name: ONNX model name prefix, generated in main_hardware:gen_prof()
            net_config:   Profiling network configuration, assembled or sampled
            result_dir:   Output directory for ONNX models and configurations
        """
        
        search_space = _init_component(net_config, "search_space")
        assert isinstance(search_space, GeneralSearchSpace)
        
        primitives = net_config['final_model_cfg']['genotypes']
        sub_primitives = primitives[1:] # exclude first 3x3 conv
        sub_primitives = [[prim] for prim in sub_primitives if prim['prim_type'] != 'conv_1x1'] # exclude glue layers
        
        all_primitives = [("whole", primitives)] + list(enumerate(sub_primitives))

        for prim_idx, prim in all_primitives:

            net_config['final_model_cfg']['genotypes'] = prim
            model = _init_component(
                net_config,
                "final_model",
                search_space=search_space,
                device="cuda:{}".format(self.gpu),
            )

            shape_info = "x".join([str(x) for x in [prim[0]["C"], prim[0]["spatial_size"],
                prim[0]["spatial_size"]]])
            onnx_name = os.path.join(result_dir, compile_name + f'_{prim_idx}@{shape_info}.onnx')
            prim_name = os.path.join(result_dir, compile_name + f'_{prim_idx}@{shape_info}.yaml')
            
            dummy_input = torch.randn(1, prim[0]['C'], prim[0]['spatial_size'], prim[0]['spatial_size'], device="cuda:{}".format(self.gpu))
            torch.onnx.export(
                model,
                dummy_input,
                onnx_name,
                verbose=False
            )

            with open(prim_name, 'w') as f:
                yaml.dump(prim, f)

            self.logger.info(f'generated ONNX model: {onnx_name}')


    def parse_file(
        self,
        prof_result_file,
        prof_prim_file,
        prim_to_ops_file,
        result_dir,
        perf_fn=None,
        perf_names=("latency",),
    ):
        """
            Reads TensorRT output print files, remove outlier data points, 
            and write parsed result to output directory.

            prof_result_file: (str) input dir, contains all TensorRT output files, names must match with ONNX models.
            prof_prim_file:   (str) a list of all search space primitives, generated by compile(). Unused argument, remained to conform to base compiler interface
            prim_to_ops_file: (str) xavier ONNX direct parent folder. e.g.: compile_result/hardwares/0-xavier. This argument's name remains unchanged to conform to the base compiler's interface.
            result_dir:       (str) parse result output directory
            perf_fn:          unused argument, remained to conform to the base compiler interface 
            perf_names:       (iteratable of str) defined in hardware configuration file, the performance type name. e.g. latency.
        """
        self.logger.info("xavier result parsing start...")
        for _dir in os.listdir(prim_to_ops_file):
            curr_dir = os.path.join(prim_to_ops_file, _dir)
            if os.path.isdir(curr_dir):
                r_dir = os.path.join(result_dir, _dir)
                os.makedirs(r_dir, exist_ok=True)
                # for each assembled profiling net
                # collect all primitives' configuration
                prim_config_files = glob(os.path.join(prim_to_ops_file, _dir, '*.yaml'))
                # go through each primitive configuration
                result_dict = dict()
                result_dict['overall_latency'] = 0
                result_dict['primitives'] = list()
                for prim_config_file in prim_config_files:
                    basename = os.path.basename(prim_config_file)
                    basename = os.path.splitext(basename)[0]
                    result_file = os.path.join(prof_result_file, basename + '.txt')
                    prim_config = self._parse_one_primitive(prim_config_file, result_file)
                    if 'whole' in basename:
                        result_dict['overall_latency'] = prim_config[0]['performances']['latency']
                    else:
                        result_dict['primitives'] += prim_config
                result_name = os.path.join(r_dir, _dir + '.yaml')
                with open(result_name, 'w') as f:
                    yaml.safe_dump(result_dict, f)
                self.logger.info('genrated parsed result: ' + result_name)


    def _parse_one_primitive(self, prim_config_file, latency_result_file):
        """ return a dictionary, adding 'latency' entry in primitive's configuration """
        # load primitive's configuration dictionary
        with open(prim_config_file, 'r') as f:
            prim_config = yaml.load(f)
        
        latency_data = self._read_xavier_latency_file(latency_result_file)
        latency_data = self._clean_data(latency_data)
        average_latency = sum(latency_data) / len(latency_data)
        prim_config[0]['performances'] = dict()
        prim_config[0]['performances']['latency'] = average_latency
        return prim_config


                                
            
    def _clean_data(self, data, bin_size=0.0001, thresh=0.1):
        """ remove outlier """
        start = int(min(data) / bin_size) * bin_size
        bin_num = int((max(data) - min(data)) / bin_size) + 1
        bins = list()
        for _ in range(bin_num):
            bins.append(list())

        for index, bin in enumerate(bins):
            lower_bound = start + index * bin_size
            upper_bound = lower_bound + bin_size
            for _ in data:
                if not _ >= lower_bound: continue
                if not _ <  upper_bound: continue
                bin.append(_)
        max_index = -1
        max_value = -1
        for index, bin in enumerate(bins):
            height = len(bin)
            if height > max_value:
                max_value = height
                max_index = index 
        
        # plot caculation range
        upper_bound = -1
        for index in range(max_index,len(bins)):
            x = start + index * bin_size
            height = len(bins[index])
            if height < thresh * max_value:
                upper_bound = x
                break
        lower_bound = 0
        for index in range(max_index, 0, -1):
            x = start + index * bin_size
            height = len(bins[index])
            if height < thresh * max_value:
                lower_bound = x
                break
        
        return [datum for datum in data if datum >= lower_bound and datum <= upper_bound]


    def _read_xavier_latency_file(self, latency_file):
        "given a latency result file, return a list of latency values"
        data = list()
        with open(latency_file, 'r') as f:
            for line in f.readlines():
                if 'GPU latency' not in line: continue
                latency_str = line.split('-')[2]
                latency_str = latency_str.replace('GPU latency:','')
                latency_str = latency_str.replace('ms', '')
                latency_str = re.split(f'\s+', latency_str)
                latency_str = [s for s in latency_str if s != '']
                if len(latency_str) == 0: continue
                latency = float( latency_str[0] )
                data.append(latency)
        return data




