from torch.utils.data import Dataset, DataLoader
import numpy as np
import torch
import cv2
import pickle
import os
from easydict import EasyDict as edict
from data.base_dataset import BaseDataset
import sys
import random
PALM_COLOR = [1]*3
THUMB_COLOR1 = [2]*3
THUMB_COLOR2 = [3]*3
THUMB_COLOR3 = [4]*3
INDEX_COLOR1 = [5]*3
INDEX_COLOR2 = [6]*3
INDEX_COLOR3 = [7]*3
MIDDLE_COLOR1 = [8]*3
MIDDLE_COLOR2 = [9]*3
MIDDLE_COLOR3 = [10]*3
RING_COLOR1 = [11]*3
RING_COLOR2 = [12]*3
RING_COLOR3 = [13]*3
PINKY_COLOR1 = [14]*3
PINKY_COLOR2 = [15]*3
PINKY_COLOR3 = [16]*3


def generate_jointsmap(uv_coord, depth, width, height, channel=3):
    canvas = np.ones((height, width, channel)) * sys.maxsize
    _canvas = canvas.copy()
    bones = [

        ((0, 17), [160] * channel),
        ((0, 1), [170] * channel),
        ((0, 5), [180] * channel),
        ((0, 9), [190] * channel),
        ((0, 13), [200] * channel),

        ((17, 18), [130] * channel),
        ((18, 19), [140] * channel),
        ((19, 20), [150] * channel),

        ((1, 2), [10] * channel),
        ((2, 3), [20] * channel),
        ((3, 4), [30] * channel),

        ((5, 6), [40] * channel),
        ((6, 7), [50] * channel),
        ((7, 8), [60] * channel),

        ((9, 10), [70] * channel),
        ((10, 11), [80] * channel),
        ((11, 12), [90] * channel),

        ((13, 14), [100] * channel),
        ((14, 15), [110] * channel),
        ((15, 16), [120] * channel),
    ]

    for connection, color in bones:
        temp_canvas = np.ones(canvas.shape) * sys.maxsize

        coord1 = uv_coord[connection[0]]
        coord2 = uv_coord[connection[1]]

        coords = np.stack([coord1, coord2])
        avg_depth = (depth[connection[0]] + depth[connection[1]]) / 2
        x = coords[:, 0]
        y = coords[:, 1]
        mX = x.mean()
        mY = y.mean()
        length = ((x[0] - x[1]) ** 2 + (y[0] - y[1]) ** 2) ** 0.5
        angle = np.math.degrees(np.math.atan2(y[0] - y[1], x[0] - x[1]))
        radius = 5
        polygon = cv2.ellipse2Poly((int(mX), int(mY)), (int(length / 2), radius), int(angle), 0, 360, 1)
        cv2.fillConvexPoly(temp_canvas, polygon, [avg_depth] * channel)
        _canvas = np.minimum(_canvas, temp_canvas)
        canvas[_canvas == avg_depth] = color[0]
    canvas[canvas==sys.maxsize] = 0
    return canvas


class STBdataset(BaseDataset):
    def __init__(self, opt):
        """ STB dataset for dataset processed by create_STB_DP.py
        :param path: path to dataset (assuming this is the file folder generated by create_MHP_DB.py
        :param mode: paired (depthmap and rgb) or unpaired (rgb and random depth) or heatmap
        :param kwargs:
        """
        super(STBdataset, self).__init__(opt)

        # if self.opt.dataset_mode not in ['aligned', 'unaligned', 'heatmap',  'jointsAligned', 'jointsAligned2',
                                         # "jointsUnaligned", "hand3d"]:
            # raise ValueError

        # self.mode = self.opt.dataset_mode
        self.opt = opt
        self.root_dir = self.opt.dataroot
        with open(os.path.join(self.root_dir, "annotation.pickle"), "rb") as handle:
            self.annotations = pickle.load(handle)

        self.image_BB = []
        self.image_joints_BB = []
        self.image_heatmaps_BB = []
        self.image_color_SK = []
        self.image_color_heatmaps_SK = []
        self.image_color_joints_SK = []
        self.image_depth_SK = []
        self.image_depth_joints_SK = []
        self.image_depth_heatmaps_SK = []
        for folder in self.annotations.keys():
            for image in self.annotations[folder].keys():
                img_path = os.path.join(self.root_dir, folder, image)
                camera, spec, n = image.split('_')
                if camera == 'BB':
                    self.image_BB.append(img_path)
                    self.image_joints_BB.append(
                        os.path.join(self.root_dir, folder, camera + "_" + spec + "_" + "joints" + "_" + n)
                    )
                    self.image_heatmaps_BB.append(img_path[0:-3]+"pt")
                else:
                    if spec == 'color':
                        # create pair SK_color / SK_depth
                        self.image_color_SK.append(img_path)
                        self.image_color_heatmaps_SK.append(img_path[0:-3] + "pt")
                        self.image_color_joints_SK.append(os.path.join(
                            self.root_dir, folder, camera + "_" + spec + "_" + "joints" + "_" + n))
                        # if not os.path.isfile(self.image_color_joints_SK[-1]):
                        #     print(self.annotations[folder][image].jointsmap)
                        #     raise ValueError
                        self.image_depth_SK.append(
                            os.path.join(self.root_dir, folder, camera + "_" + "depth" + "_" + n))
                        self.image_depth_heatmaps_SK.append(
                            os.path.join(self.root_dir, folder, camera + "_" + "depth" + "_" + n[0:-3]+"pt")
                        )
                        self.image_depth_joints_SK.append(
                            os.path.join(self.root_dir, folder, camera + "_" + "depth" + "_" + "joints" + "_" + n)
                        )
                    else:
                        continue

        self.image_color_SK_BB = self.image_color_SK + self.image_BB
        self.image_heatmaps_SK_BB = self.image_color_heatmaps_SK + self.image_heatmaps_BB
    def __len__(self):
        return len(self.image_color_SK)


    def __getitem__(self, item):
        random_item = random.randint(0, self.__len__()-1)
        P1 = self.get_item_aligned(random_item)
        P2 = self.get_item_aligned(item)

        return {"P1":P1['A'], "BP1":P1["B"], "P2":P2['A'], "BP2":P2["B"],
                "P1_path":P1['path'], "P2_path":P2['path'], "P1xyz":P1['xyz'],
                "P2xyz":P2['xyz']}


    def name(self):
        return 'handDataSet'


    def get_item_aligned(self, item):
        P_name = self.image_color_SK[item]
        P1_img = self.to_tensor(self.norm(cv2.imread(P_name), 'bgr'))
        P1_labels = self.get_labels(P_name)
        # BP1_img = self.to_tensor(self.norm(generate_jointsmap(P1_labels['uv_coord'],P1_labels['depth'], 256, 256,
                                                                # 3,) ,'bgr'))
        uv_coord = P1_labels['uv_coord']
        BP1_img = self.get_heatmaps(P1_labels['uv_coord'],
                                                     [256, 256], 5)
        uv = torch.tensor(uv_coord)
        z = torch.tensor(P1_labels['depth']).unsqueeze(dim=-1)
        xyz = torch.cat([uv, z], dim=-1)
        batch = {}
        batch['B'] = BP1_img
        batch['A'] = P1_img
        batch['path'] = P_name
        batch['xyz'] = xyz
        return  batch

    def get_heatmaps(self, uv_coords, shape, sigma):
        heatmaps = []
        for x, y in uv_coords:
            heatmaps.append(self.to_tensor(self.gen_heatmap(x, y, shape, sigma).astype(np.float32)))
        heatmaps = torch.stack(heatmaps)
        heatmaps = heatmaps.squeeze(1)

        return heatmaps

    @staticmethod
    def to_tensor(image):
        shape = image.shape
        if shape[-1] == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = torch.from_numpy(image)
            image = image.permute(2, 0, 1)
        else:
            # grayscale
            image = torch.from_numpy(image)
            image = image.unsqueeze(0)
        return image

    def norm(self, input, encoding):
        """
        normalize a given image.
        :param input:
        :param encoding: either 'rgb' or 'depth'. STB dataset encodes depth information with rgb values.
        :return:
        """
        if encoding == 'bgr':
            # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            norm_image = cv2.normalize(input, dst=None, alpha=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)
            return norm_image
            # return gray / np.linalg.norm(gray)
        elif encoding == 'depth':
            # depth formula is given by the author.
            b, g, r = input[:, :, 0], input[:, :, 1], input[:, :, 2]
            input = r + g * 256.0
            norm_image = cv2.normalize(input, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)
            # return depth / np.linalg.norm(depth)
            return norm_image
        elif encoding == 'linear':
            return cv2.normalize(input, None, 0, 1, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
        else:
            raise NotImplemented

    def get_labels(self, image_path):
        *_, folder, name = image_path.split('/')
        if "joints" in name:
            name = name.split('_')
            name = name[0] + "_" + name[1] + "_" + name[-1]
        return self.annotations[folder][name]

    def gen_heatmap(self, x, y, shape, sigma):
        # base on DGGAN description
        # a heat map is a dirac-delta function on (x,y) with Gaussian Distribution sprinkle on top.
        centermap = np.zeros((shape[0], shape[1], 1), dtype=np.float32)
        center_map = self.gaussian_kernel(shape[0], shape[1], x, y, sigma)
        center_map[center_map>1]=1
        center_map[center_map<0.0099]=0
        centermap[:, :, 0] = center_map
        return center_map

    @staticmethod
    def draw(image, uv_coord, bbox=None):
        """
        draw image with uv_coord and an optional bounding box
        :param image:
        :param uv_coord:
        :param bbox:
        :return: image
        """
        for i, p in enumerate(uv_coord):
            x, y = p
            cv2.circle(image, (int(x), int(y)), 2, 255, 1)
            cv2.putText(image, str(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, 255)
        if bbox is not None:
            cv2.rectangle(image, (bbox[0], bbox[3]), (bbox[1], bbox[2]), 255, 2)
        return image

    @staticmethod
    def gaussian_kernel(width, height, x, y, sigma):
        gridy, gridx = np.mgrid[0:height, 0:width]
        D2 = (gridx - x) ** 2 + (gridy - y) ** 2
        return np.exp(-D2 / 2.0 / sigma / sigma)

if __name__ == "__main__":
    opt = edict()
    opt.dataroot = "../datasets/STB_process/train"
    dataset = STBdataset(opt)
    for i in range(len(dataset)):
        sample = dataset[i]



