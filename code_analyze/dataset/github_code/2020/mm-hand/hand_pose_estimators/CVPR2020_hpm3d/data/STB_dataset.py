from torch.utils.data import Dataset, DataLoader
import numpy as np
import torch
import cv2
import pickle
import os
from easydict import EasyDict as edict
from data.base_dataset import BaseDataset
import sys
import random
PALM_COLOR = [1]*3
THUMB_COLOR1 = [2]*3
THUMB_COLOR2 = [3]*3
THUMB_COLOR3 = [4]*3
INDEX_COLOR1 = [5]*3
INDEX_COLOR2 = [6]*3
INDEX_COLOR3 = [7]*3
MIDDLE_COLOR1 = [8]*3
MIDDLE_COLOR2 = [9]*3
MIDDLE_COLOR3 = [10]*3
RING_COLOR1 = [11]*3
RING_COLOR2 = [12]*3
RING_COLOR3 = [13]*3
PINKY_COLOR1 = [14]*3
PINKY_COLOR2 = [15]*3
PINKY_COLOR3 = [16]*3


def generate_jointsmap(uv_coord, depth, width, height, channel=3):
    canvas = np.ones((height, width, channel)) * sys.maxsize
    _canvas = canvas.copy()
    bones = [

        ((0, 17), [160] * channel),
        ((0, 1), [170] * channel),
        ((0, 5), [180] * channel),
        ((0, 9), [190] * channel),
        ((0, 13), [200] * channel),

        ((17, 18), [130] * channel),
        ((18, 19), [140] * channel),
        ((19, 20), [150] * channel),

        ((1, 2), [10] * channel),
        ((2, 3), [20] * channel),
        ((3, 4), [30] * channel),

        ((5, 6), [40] * channel),
        ((6, 7), [50] * channel),
        ((7, 8), [60] * channel),

        ((9, 10), [70] * channel),
        ((10, 11), [80] * channel),
        ((11, 12), [90] * channel),

        ((13, 14), [100] * channel),
        ((14, 15), [110] * channel),
        ((15, 16), [120] * channel),
    ]

    for connection, color in bones:
        temp_canvas = np.ones(canvas.shape) * sys.maxsize

        coord1 = uv_coord[connection[0]]
        coord2 = uv_coord[connection[1]]

        coords = np.stack([coord1, coord2])
        avg_depth = (depth[connection[0]] + depth[connection[1]]) / 2
        x = coords[:, 0]
        y = coords[:, 1]
        mX = x.mean()
        mY = y.mean()
        length = ((x[0] - x[1]) ** 2 + (y[0] - y[1]) ** 2) ** 0.5
        angle = np.math.degrees(np.math.atan2(y[0] - y[1], x[0] - x[1]))
        radius = 5
        polygon = cv2.ellipse2Poly((int(mX), int(mY)), (int(length / 2), radius), int(angle), 0, 360, 1)
        cv2.fillConvexPoly(temp_canvas, polygon, [avg_depth] * channel)
        _canvas = np.minimum(_canvas, temp_canvas)
        canvas[_canvas==avg_depth] = color[0]
    canvas[canvas==sys.maxsize] = 0
    return canvas

class STBdataset(BaseDataset):
    def __init__(self, opt):
        """ STB dataset for dataset processed by create_STB_DP.py
        :param path: path to dataset (assuming this is the file folder generated by create_MHP_DB.py
        :param mode: paired (depthmap and rgb) or unpaired (rgb and random depth) or heatmap
        :param kwargs:
        """
        super(STBdataset, self).__init__(opt)

        # if self.opt.dataset_mode not in ['aligned', 'unaligned', 'heatmap',  'jointsAligned', 'jointsAligned2',
                                         # "jointsUnaligned", "hand3d"]:
            # raise ValueError

        # self.mode = self.opt.dataset_mode

        self.root_dir = self.opt.dataroot
        if self.opt.isTrain:
            with open(os.path.join(self.root_dir, "stb_annotation_train.pickle"), "rb") as handle:
                self.annotations = pickle.load(handle)
        else:
            with open(os.path.join(self.root_dir, "stb_annotation_test.pickle"), "rb") as handle:
                self.annotations = pickle.load(handle)

        self.image_BB = []
        self.image_joints_BB = []
        self.image_heatmaps_BB = []
        self.image_color_SK = []
        self.image_color_heatmaps_SK = []
        self.image_color_joints_SK = []
        self.image_depth_SK = []
        self.image_depth_joints_SK = []
        self.image_depth_heatmaps_SK = []
        for folder in self.annotations.keys():
            for image in self.annotations[folder].keys():
                img_path = os.path.join(self.root_dir, folder, image)
                camera, spec, n = image.split('_')
                if camera == 'BB':
                    self.image_BB.append(img_path)
                    self.image_joints_BB.append(
                        os.path.join(self.root_dir, folder, camera + "_" + spec + "_" + "joints" + "_" + n)
                    )
                    self.image_heatmaps_BB.append(img_path[0:-3]+"pt")
                else:
                    if spec == 'color':
                        # create pair SK_color / SK_depth
                        self.image_color_SK.append(img_path)
                        self.image_color_heatmaps_SK.append(img_path[0:-3] + "pt")
                        self.image_color_joints_SK.append(os.path.join(
                            self.root_dir, folder, camera + "_" + spec + "_" + "joints" + "_" + n))
                        # if not os.path.isfile(self.image_color_joints_SK[-1]):
                        #     print(self.annotations[folder][image].jointsmap)
                        #     raise ValueError
                        self.image_depth_SK.append(
                            os.path.join(self.root_dir, folder, camera + "_" + "depth" + "_" + n))
                        self.image_depth_heatmaps_SK.append(
                            os.path.join(self.root_dir, folder, camera + "_" + "depth" + "_" + n[0:-3]+"pt")
                        )
                        self.image_depth_joints_SK.append(
                            os.path.join(self.root_dir, folder, camera + "_" + "depth" + "_" + "joints" + "_" + n)
                        )
                    else:
                        continue
        if self.opt.isTrain:
            self.augmention_method= self.opt.augmentation_method

            path = self.opt.dataroot.split('/')[0:-1]
            path[-1] = f"{self.augmention_method}_{path[-1]}"
            self.augmentation_dir = '/'.join(path)
            self.augmentation_map = np.zeros(self.__len__(), dtype=np.bool)
            print(f"augmentation_dir is {self.augmentation_dir}")

            # import pdb; pdb.set_trace()
            n = int((1-self.opt.augmentation_ratio) * self.__len__()) # number of augmented image
            random_sample = random.sample([i for i in range(self.__len__())], n)
            self.augmentation_map[random_sample] = True

    def __len__(self):
        return len(self.image_color_SK)


    def __getitem__(self, item):
        if self.opt.isTrain:
            if (self.opt.dataset_mode == 'hpm') :
                return self.get_item_hpm(item)
            else:
                return self.get_item_aligned(item)
        else:
            return self.get_item_test(item)

    def _get_item_default(self, item):
        return self._get_item_aligned(item)

    def get_item_test(self,item):
        image_path = self.image_color_SK[item]
        image = self.to_tensor(self.norm(cv2.imread(image_path), 'bgr'))
        image_labels = self.get_labels(image_path)
        depth_norm = np.expand_dims(image_labels['depth'] / 700, -1) * 256
        uv_coord = image_labels['uv_coord']
        pseudo_xyz = np.concatenate([uv_coord, depth_norm], 1)
        batch = {}
        batch['A'] = image
        batch['B'] = torch.tensor(pseudo_xyz)
        return batch

    def get_item_hpm(self, item):
        image_path = self.image_color_SK[item]
        instance_weight = 1
        if self.augmentation_map[item]:
            *_, folder, name = image_path.split('/')
            if self.augmention_method == "None":
                image = self.to_tensor(self.norm(np.random.random((256, 256, 3))))
                instance_weight = 0
            else:
                aug_path = os.path.join(self.augmentation_dir, folder, name)
                if not os.path.isfile(image_path): raise ValueError
                image = self.to_tensor(self.norm(cv2.imread(aug_path), 'bgr'))
        else:
            image = self.to_tensor(self.norm(cv2.imread(image_path), 'bgr'))
        image_labels = self.get_labels(image_path)
        joint_heatmaps = self.get_heatmaps(image_labels['uv_coord'], [256, 256], 5)
        depth_norm = image_labels['depth'] / 700
        batch = {}
        batch['A'] = image
        batch['B'] = joint_heatmaps
        batch['C'] = torch.tensor(depth_norm, dtype=torch.float32)
        batch['D'] = torch.tensor(instance_weight, dtype=torch.int32)
        batch['E'] = image_path
        batch['F'] = torch.tensor(image_labels['uv_coord'])
        return batch
    def get_item_aligned(self, item):
        color_image_path = self.image_color_SK[item]
        color_image = self.to_tensor(self.norm(cv2.imread(color_image_path), 'bgr'))
        color_labels = self.get_labels(color_image_path)
        joint_map = self.to_tensor(self.norm(generate_jointsmap(color_labels['uv_coord'],color_labels['depth'], 256, 256,
                                                                3,) ,'bgr'))
        batch = {}
        batch['A'] = joint_map
        batch['B'] = color_image
        return  batch

    def get_heatmaps(self, uv_coords, shape, sigma):
        heatmaps = []
        for x, y in uv_coords:
            heatmaps.append(self.to_tensor(self.gen_heatmap(x, y, shape, sigma).astype(np.float32)))
        heatmaps = torch.stack(heatmaps)
        heatmaps = heatmaps.squeeze(1)
        return heatmaps

    @staticmethod
    def to_tensor(image):
        shape = image.shape
        if shape[-1] == 3:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = torch.from_numpy(image)
            image = image.permute(2, 0, 1)
        else:
            # grayscale
            image = torch.from_numpy(image)
            image = image.unsqueeze(0)
        return image

    def norm(self, input, encoding):
        """
        normalize a given image.
        :param input:
        :param encoding: either 'rgb' or 'depth'. STB dataset encodes depth information with rgb values.
        :return:
        """
        if encoding == 'bgr':
            # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            norm_image = cv2.normalize(input, dst=None, alpha=1.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)
            return norm_image
            # return gray / np.linalg.norm(gray)
        elif encoding == 'depth':
            # depth formula is given by the author.
            b, g, r = input[:, :, 0], input[:, :, 1], input[:, :, 2]
            input = r + g * 256.0
            norm_image = cv2.normalize(input, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)
            # return depth / np.linalg.norm(depth)
            return norm_image
        elif encoding == 'linear':
            return cv2.normalize(input, None, 0, 1, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
        else:
            raise NotImplemented

    def get_labels(self, image_path):
        *_, folder, name = image_path.split('/')
        if "joints" in name:
            name = name.split('_')
            name = name[0] + "_" + name[1] + "_" + name[-1]
        return self.annotations[folder][name]

    def gen_heatmap(self, x, y, shape, sigma):
        # base on DGGAN description
        # a heat map is a dirac-delta function on (x,y) with Gaussian Distribution sprinkle on top.
        centermap = np.zeros((shape[0], shape[1], 1), dtype=np.float32)
        center_map = self.gaussian_kernel(shape[0], shape[1], x, y, sigma)
        center_map[center_map>1]=1
        center_map[center_map<0.0099]=0
        centermap[:, :, 0] = center_map
        return center_map

    @staticmethod
    def draw(image, uv_coord, bbox=None):
        """
        draw image with uv_coord and an optional bounding box
        :param image:
        :param uv_coord:
        :param bbox:
        :return: image
        """
        for i, p in enumerate(uv_coord):
            x, y = p
            cv2.circle(image, (int(x), int(y)), 2, 255, 1)
            cv2.putText(image, str(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, 255)
        if bbox is not None:
            cv2.rectangle(image, (bbox[0], bbox[3]), (bbox[1], bbox[2]), 255, 2)
        return image

    @staticmethod
    def gaussian_kernel(width, height, x, y, sigma):
        gridy, gridx = np.mgrid[0:height, 0:width]
        D2 = (gridx - x) ** 2 + (gridy - y) ** 2
        return np.exp(-D2 / 2.0 / sigma / sigma)

if __name__ == "__main__":
    a = np.zeros((2,2))

